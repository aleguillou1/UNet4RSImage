{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.transform import from_origin\n",
    "import geopandas as gpd\n",
    "import cv2\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 : Patch Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image_path, label_path, shapefile_path, output_dir, train_ratio=0.75, val_ratio=0.2, test_ratio=0.05):\n",
    "    \n",
    "    with rasterio.open(image_path) as src_img:\n",
    "        \n",
    "        with rasterio.open(label_path) as src_lbl:\n",
    "            \n",
    "            grid = gpd.read_file(shapefile_path) #Load the satellite image, load the labels, and then the grid containing the patches. \n",
    "            \n",
    "            train_img_dir = os.path.join(output_dir, 'train/images')\n",
    "            val_img_dir = os.path.join(output_dir, 'validation/images')\n",
    "            test_img_dir = os.path.join(output_dir, 'test/images')\n",
    "\n",
    "            train_lbl_dir = os.path.join(output_dir, 'train/labels')\n",
    "            val_lbl_dir = os.path.join(output_dir, 'validation/labels')\n",
    "            test_lbl_dir = os.path.join(output_dir, 'test/labels')\n",
    "            #Create the train, validation, and test directories if they do not already exist.\n",
    "            \n",
    "            for dir_path in [train_img_dir, val_img_dir, test_img_dir, train_lbl_dir, val_lbl_dir, test_lbl_dir]:\n",
    "                if not os.path.exists(dir_path):\n",
    "                    os.makedirs(dir_path)\n",
    "\n",
    "            \n",
    "            indices = list(grid.index)\n",
    "            random.shuffle(indices)\n",
    "            # Shuffle the patch indices for a random distribution\n",
    "            \n",
    "            num_patches = len(indices)\n",
    "            num_train = int(train_ratio * num_patches)\n",
    "            num_val = int(val_ratio * num_patches)\n",
    "            num_test = num_patches - num_train - num_val\n",
    "            # Calculate the sizes of the train, validation, and test sets.\n",
    "            \n",
    "            train_indices = indices[:num_train]\n",
    "            val_indices = indices[num_train:num_train + num_val]\n",
    "            test_indices = indices[num_train + num_val:]\n",
    "\n",
    "            \n",
    "            def save_patch_and_label(patch, label, transform, output_img_subdir, output_lbl_subdir, patch_filename):\n",
    "                \n",
    "                patch_img_path = os.path.join(output_img_subdir, patch_filename)\n",
    "                with rasterio.open(\n",
    "                    patch_img_path, 'w',\n",
    "                    driver='GTiff',\n",
    "                    height=224, width=224,\n",
    "                    count=4, dtype=patch.dtype, #Set the count variable according to the number of spectral bands you have.\n",
    "                    crs=src_img.crs, transform=transform\n",
    "                ) as dst_img:\n",
    "                    dst_img.write(patch)\n",
    "                print(f\"Image patch {patch_filename} saved in {output_img_subdir}.\")\n",
    "\n",
    "                \n",
    "                patch_lbl_path = os.path.join(output_lbl_subdir, patch_filename)\n",
    "                with rasterio.open(\n",
    "                    patch_lbl_path, 'w',\n",
    "                    driver='GTiff',\n",
    "                    height=224, width=224,\n",
    "                    count=1, dtype=label.dtype,  # Single channel for labels\n",
    "                    crs=src_lbl.crs, transform=transform\n",
    "                ) as dst_lbl:\n",
    "                    dst_lbl.write(label[0, :, :], 1)  # Correcting the write operation\n",
    "                print(f\"Label patch {patch_filename} saved in {output_lbl_subdir}.\")\n",
    "\n",
    "            \n",
    "            for idx, row in grid.iterrows():\n",
    "                geom = [row['geometry']]\n",
    "                auto_value = row['AUTO']\n",
    "\n",
    "                # Extract the patch for the image\n",
    "                patch_img, transform = mask(src_img, geom, crop=True)\n",
    "                patch_lbl, _ = mask(src_lbl, geom, crop=True)\n",
    "\n",
    "                # Check the patch size and resize if necessary (for the image and the label)\n",
    "                height_img, width_img = patch_img.shape[1], patch_img.shape[2]\n",
    "                height_lbl, width_lbl = patch_lbl.shape[1], patch_lbl.shape[2]\n",
    "                \n",
    "                if height_img != 224 or width_img != 224:\n",
    "                    resized_patch_img = np.zeros((6, 224, 224), dtype=patch_img.dtype)\n",
    "                    for i in range(6):\n",
    "                        resized_patch_img[i] = cv2.resize(patch_img[i], (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "                    patch_img = resized_patch_img\n",
    "                \n",
    "                if height_lbl != 224 or width_lbl != 224:\n",
    "                    resized_patch_lbl = cv2.resize(patch_lbl[0], (224, 224), interpolation=cv2.INTER_NEAREST)\n",
    "                    patch_lbl = resized_patch_lbl[np.newaxis, :, :]  # Add channel dimension\n",
    "                \n",
    "                # Determine the directory to save the patch\n",
    "                patch_filename = f\"patch_{auto_value}.tif\"\n",
    "                if idx in train_indices:\n",
    "                    save_patch_and_label(patch_img, patch_lbl, transform, train_img_dir, train_lbl_dir, patch_filename)\n",
    "                elif idx in val_indices:\n",
    "                    save_patch_and_label(patch_img, patch_lbl, transform, val_img_dir, val_lbl_dir, patch_filename)\n",
    "                elif idx in test_indices:\n",
    "                    save_patch_and_label(patch_img, patch_lbl, transform, test_img_dir, test_lbl_dir, patch_filename)\n",
    "\n",
    "    print(\"Patch and label extraction completed, and distribution performed.\")\n",
    "\n",
    "# Utilisation de la fonction\n",
    "image_path = \"path/to/your/Image.tif\"\n",
    "label_path = \"path/to/your/Label.tif\"\n",
    "shapefile_path = \"path/to/your/Grid.shp\"\n",
    "output_dir = \"path/to/your/repo/Patch\"\n",
    "extract_patches(image_path, label_path, shapefile_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 : Images pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def normalize_img(img):\n",
    "    return img / np.max(img)\n",
    "\n",
    "# Function to read .tif files and convert them into tensors\n",
    "def load_data(image_dir, mask_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if img_file.endswith('.tif') or img_file.endswith('.tiff'):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            mask_path = os.path.join(mask_dir, img_file)\n",
    "            \n",
    "            # Read images and masks\n",
    "            img = tiff.imread(img_path).astype(np.float32)\n",
    "            mask = tiff.imread(mask_path).astype(np.uint8)\n",
    "            \n",
    "            img = normalize_img(img)\n",
    "            \n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "    \n",
    "    # Convert the lists into numpy arrays\n",
    "    images = np.array(images)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    # Convert numpy arrays into tensors\n",
    "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
    "    masks = tf.convert_to_tensor(masks, dtype=tf.uint8)\n",
    "    \n",
    "    return images, masks\n",
    "\n",
    "train_image_dir = '/Patch/train/images'\n",
    "train_mask_dir = '/Patch/train/labels'\n",
    "val_image_dir = '/Patch/validation/images/'\n",
    "val_mask_dir = '/Patch/validation/labels'\n",
    "\n",
    "\n",
    "# Load and transform the training data\n",
    "train_images, train_masks = load_data(train_image_dir, train_mask_dir)\n",
    "val_images, val_masks = load_data(val_image_dir, val_mask_dir)\n",
    "\n",
    "print(f'Shape of training images: {train_images.shape}')\n",
    "print(f'Shape of training labels: {train_masks.shape}')\n",
    "\n",
    "# Check the pixel values of the images\n",
    "print(f'Minimum and maximum values of the training images: {tf.reduce_min(train_images).numpy()}, {tf.reduce_max(train_images).numpy()}')\n",
    "print(f'Minimum and maximum values of the training labels: {tf.reduce_min(train_masks).numpy()}, {tf.reduce_max(train_masks).numpy()}')\n",
    "\n",
    "print(f'Minimum and maximum values of the validation images: {tf.reduce_min(val_images).numpy()}, {tf.reduce_max(val_images).numpy()}')\n",
    "print(f'Minimum and maximum values of the validation labels: {tf.reduce_min(val_masks).numpy()}, {tf.reduce_max(val_masks).numpy()}')\n",
    "\n",
    "# Display an RGB image and its corresponding mask\n",
    "idx = 17  # You can change this index to visualize other images\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(train_images[idx][:, :, :3])  \n",
    "plt.title('Training image (RGB)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(train_masks[idx], cmap='gray') \n",
    "plt.title('training label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 : Train of the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unet_advanced(input_shape, num_classes=6):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Encodeur\n",
    "    conv1 = Conv2D(64, 3, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(64, 3, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(128, 3, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(256, 3, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(512, 3, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(1024, 3, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
    "    merge6 = Concatenate()([conv4, up6])\n",
    "    conv6 = Conv2D(512, 3, padding='same')(merge6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(512, 3, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    merge7 = Concatenate()([conv3, up7])\n",
    "    conv7 = Conv2D(256, 3, padding='same')(merge7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(256, 3, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    merge8 = Concatenate()([conv2, up8])\n",
    "    conv8 = Conv2D(128, 3, padding='same')(merge8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(128, 3, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    \n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    merge9 = Concatenate()([conv1, up9])\n",
    "    conv9 = Conv2D(64, 3, padding='same')(merge9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(64, 3, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "\n",
    "    outputs = Conv2D(num_classes, 1, activation='softmax')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the parameters\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "num_channels = 4  # Variable to select the number of input channels\n",
    "num_classes = 6   # Here is the number of classes you need to predict +1\n",
    "batch_size = 4   # Reduce the batch size to decrease memory usage\n",
    "\n",
    "# Initialize the U-Net model\n",
    "input_shape = (img_height, img_width, num_channels)\n",
    "model = unet_advanced(input_shape, num_classes=num_classes)\n",
    "model.summary()\n",
    "\n",
    "# Define the callback to save the best epoch\n",
    "saved_model_path = \"/path/to/your/saved_model\"\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=saved_model_path,  # Path to save the best model\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_format=\"tf\",  # Ensure SavedModel format\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model with the callback\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    train_masks,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    validation_data=(val_images, val_masks),\n",
    "    callbacks=[checkpoint_cb]\n",
    ")\n",
    "\n",
    "print(f\"The best model has been saved in SavedModel format at {saved_model_path}.\")\n",
    "\n",
    "# After training, plot the loss and accuracy graphs\n",
    "def plot_training_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plt.savefig('/path/to/your/training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot and save the training history\n",
    "plot_training_history(history)\n",
    "\n",
    "print(\"Training history plot is saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4 : Displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the image\n",
    "def normalize_img(img):\n",
    "    return img / np.max(img)\n",
    "\n",
    "# Load a test image and keep the geo-referencing information\n",
    "def load_test_image(image_path):\n",
    "    img = tiff.imread(image_path).astype(np.float32)\n",
    "    img = normalize_img(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Read the geo-referencing info (e.g., transform and CRS)\n",
    "    with rasterio.open(image_path) as src:\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "        \n",
    "    return img, transform, crs\n",
    "\n",
    "# Load a test label\n",
    "def load_test_mask(mask_path):\n",
    "    mask = tiff.imread(mask_path).astype(np.uint8)\n",
    "    return mask\n",
    "\n",
    "# Paths to the test image and test label\n",
    "test_image_path = 'test/images/patch_1.0.tif'  \n",
    "test_mask_path = 'test/labels/patch_1.0.tif'\n",
    "\n",
    "# Load the saved model (SavedModel format)\n",
    "saved_model_path = '/path/to/your/saved_model'  # Path to the directory of the SavedModel\n",
    "model = tf.keras.models.load_model(saved_model_path)\n",
    "\n",
    "# Load and prepare the test image and test label\n",
    "test_image, transform, crs = load_test_image(test_image_path)\n",
    "test_mask = load_test_mask(test_mask_path)\n",
    "print(f'Shape of test image: {test_image.shape}')\n",
    "print(f'Shape of test mask: {test_mask.shape}')\n",
    "\n",
    "# Predict the segmentation of the test image\n",
    "prediction = model.predict(test_image)\n",
    "predicted_mask = tf.argmax(prediction, axis=-1)\n",
    "predicted_mask = tf.squeeze(predicted_mask).numpy()\n",
    "\n",
    "# Save the predicted mask with geo-referencing\n",
    "predicted_mask_path = 'example/predicted_mask.tif'  # Replace with the path where you want to save the predicted mask\n",
    "\n",
    "# Write the predicted mask using rasterio, preserving the geo-referencing\n",
    "with rasterio.open(test_image_path) as src:\n",
    "    meta = src.meta  # Get the metadata (including the transform)\n",
    "    meta.update(driver='GTiff', dtype=rasterio.uint8, count=1)  # Update the metadata to match the predicted mask's data type and single band count\n",
    "    \n",
    "    # Save the predicted mask as a georeferenced TIFF\n",
    "    with rasterio.open(predicted_mask_path, 'w', **meta) as dst:\n",
    "        dst.write(predicted_mask, 1)  # Write the predicted mask as the first band\n",
    "\n",
    "print(f'Predicted mask saved as {predicted_mask_path}')\n",
    "\n",
    "# Display the test image, the test label, and the predicted mask\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_image[0][:, :, :3])  \n",
    "plt.title('Test Image (RGB)')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(test_mask, cmap='gray')\n",
    "plt.title('Test Label')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(predicted_mask, cmap='gray')\n",
    "plt.title('Predicted Mask')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
